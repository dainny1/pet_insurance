{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scientist Skill Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(path+'/data/p1_labels.csv')\n",
    "# print(\"\\nLabels has {} unique amt_labels\".format(len(labels.amt_labeled.unique())))\n",
    "# print(\"Labels has {} unique Claim Id's\\n\".format(len(labels.ClaimId.unique())))\n",
    "\n",
    "items = pd.read_csv(path+'/data/p1_lineitems.csv')\n",
    "# print(\"\\nItems has {} unique amt_lineitem\".format(len(items.amt_lineitem.unique())))\n",
    "# print(\"Items has {} unique Claim Id's\\n\".format(len(items.ClaimId.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClaimId</th>\n",
       "      <th>id_labeled</th>\n",
       "      <th>amt_labeled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>301.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>105.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ClaimId  id_labeled  amt_labeled\n",
       "0        1           1       301.54\n",
       "1        1           2       105.00"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClaimId</th>\n",
       "      <th>id_lineitem</th>\n",
       "      <th>amt_lineitem</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>105.00</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>105.94</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ClaimId  id_lineitem  amt_lineitem features\n",
       "0        1            1        105.00        x\n",
       "1        1            2        105.94        x"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1 – Preparing a usable dataset\n",
    "\n",
    "- When we receive invoice data from our customers, it is structured by line item. \n",
    "- Trupanion then aggregates one or many line items to a higher level category for payment or denial. \n",
    "- One of our end goals is to automate this line item grouping by categorizing each invoice line item. \n",
    "- In order to do so, we must essentially undo that aggregation, so you must first map each line item to the appropriate group. \n",
    "- Our labels (in file ...labels) must be linked to our features (in file ...lineitems).\n",
    "\n",
    "Use the files named p1_labels.csv and p1_lineitems.csv to map as many line item data ids to labeled ids as possible.\n",
    "Hints:\n",
    "- “ClaimId” is a common index shared between the csvs\n",
    "- The expected solution is a list of mappings from id_lineitem to id_labeled\n",
    "- Not all line item data ids can be mapped\n",
    "- Submit your work alongside your solution\n",
    "    - We typically use python/jupyter notebook, but any similar language or tool is acceptable \n",
    "- I’ve included a “features” column as a reminder of our end goal – nothing needs to be done with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30930, 6) \n",
      "There were 9 records not matched from the data table\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClaimId</th>\n",
       "      <th>id_lineitem</th>\n",
       "      <th>amt_lineitem</th>\n",
       "      <th>features</th>\n",
       "      <th>id_labeled</th>\n",
       "      <th>amt_labeled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30921</th>\n",
       "      <td>190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>425</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30922</th>\n",
       "      <td>821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1633</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30923</th>\n",
       "      <td>1413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2753</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30924</th>\n",
       "      <td>1669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3217</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30925</th>\n",
       "      <td>1868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3597</td>\n",
       "      <td>94.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30926</th>\n",
       "      <td>1868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3598</td>\n",
       "      <td>50.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30927</th>\n",
       "      <td>1893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3645</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30928</th>\n",
       "      <td>1898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3656</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30929</th>\n",
       "      <td>2209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4214</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ClaimId  id_lineitem  amt_lineitem features  id_labeled  amt_labeled\n",
       "30921      190          NaN           NaN      NaN         425         0.00\n",
       "30922      821          NaN           NaN      NaN        1633         0.00\n",
       "30923     1413          NaN           NaN      NaN        2753         0.00\n",
       "30924     1669          NaN           NaN      NaN        3217         0.00\n",
       "30925     1868          NaN           NaN      NaN        3597        94.28\n",
       "30926     1868          NaN           NaN      NaN        3598        50.92\n",
       "30927     1893          NaN           NaN      NaN        3645         0.00\n",
       "30928     1898          NaN           NaN      NaN        3656         0.00\n",
       "30929     2209          NaN           NaN      NaN        4214         0.00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge by ClaimID, If there is no match, the missing side will contain null. \n",
    "\n",
    "df = pd.merge(items, labels, on='ClaimId', how='outer')\n",
    "print(df.shape,\"\\nThere were {} records not matched from the data table\".format(df.isnull().sum().features))\n",
    "df.loc[df.id_lineitem.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30921, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClaimId</th>\n",
       "      <th>id_lineitem</th>\n",
       "      <th>amt_lineitem</th>\n",
       "      <th>features</th>\n",
       "      <th>id_labeled</th>\n",
       "      <th>amt_labeled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>105.00</td>\n",
       "      <td>x</td>\n",
       "      <td>1</td>\n",
       "      <td>301.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>105.00</td>\n",
       "      <td>x</td>\n",
       "      <td>2</td>\n",
       "      <td>105.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>105.94</td>\n",
       "      <td>x</td>\n",
       "      <td>1</td>\n",
       "      <td>301.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>105.94</td>\n",
       "      <td>x</td>\n",
       "      <td>2</td>\n",
       "      <td>105.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12.24</td>\n",
       "      <td>x</td>\n",
       "      <td>1</td>\n",
       "      <td>301.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ClaimId  id_lineitem  amt_lineitem features  id_labeled  amt_labeled\n",
       "0        1            1        105.00        x           1       301.54\n",
       "1        1            1        105.00        x           2       105.00\n",
       "2        1            2        105.94        x           1       301.54\n",
       "3        1            2        105.94        x           2       105.00\n",
       "4        1            3         12.24        x           1       301.54"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets remove them for now\n",
    "\n",
    "df = pd.merge(items, labels, on='ClaimId', how='inner')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2 – Build a text classifier\n",
    "\n",
    "Description:\n",
    "- Our product does not cover routine, wellness or preventive care. \n",
    "- We believe that costs that pet owners can expect periodically and budget for should be separate from an insurance policy meant to cover accidents and illnesses.\n",
    "- Use the data contained in p2_data.csv to build a binary classifier to predict the “PreventiveFlag” label using the text features provided. \n",
    "- This model can be used to automate the detection of ineligible line items. \n",
    "- The expected output are prediction probabilities for rows 10001 through 11000, where the labels are currently null.\n",
    "\n",
    "\n",
    "#### This section is divided in:\n",
    "\n",
    "1. Importing customized functions and Loading Data\n",
    "2. Exploratory Data Analysis\n",
    "3. Experiment Analysis\n",
    "4. Definition of variables\n",
    "5. Comparisson of the baseline vs tuned models\n",
    "6. Training and Validation\n",
    "7. Results\n",
    "8. Prediction of the test set \n",
    "9. Conclusion\n",
    "\n",
    "It is a sequential notebook (Each cell should to be run in order). However the 8th block (Prediction of the test set) can be run after blocks 1 and 4.   \n",
    "\n",
    "Aside from this notebook and a python file with the functions used in this study, I've included 3 folders in this root folder: \n",
    "1. Data: Contains the given csv files. \n",
    "2. Graphics: Holds the images and graphs included in thiss study\n",
    "3. Results: Has the predictions of the test set in a csv file along with another csv file with the experiments results. \n",
    "\n",
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data has 2266 unique Diagnosis\n",
      "Data has 10475 unique ItemDescriptions\n",
      "Data has 3 unique PreventiveFlags:[ 0.  1. nan] \n",
      " 0.0    9322\n",
      "1.0     678\n",
      "Name: PreventiveFlag, dtype: int64\n",
      "Data has 1000 null PreventiveFlags\n",
      "\n",
      "(10000, 3) (1000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemDescription</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>PreventiveFlag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Six:  Urgent Care Exam - Daytime (8am-6pm)</td>\n",
       "      <td>colitis</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jafar:  Office Visit/Physical Exam</td>\n",
       "      <td>Stomach Issues</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ItemDescription        Diagnosis  \\\n",
       "id                                                                \n",
       "1   Six:  Urgent Care Exam - Daytime (8am-6pm)         colitis    \n",
       "2           Jafar:  Office Visit/Physical Exam  Stomach Issues    \n",
       "\n",
       "    PreventiveFlag  \n",
       "id                  \n",
       "1              0.0  \n",
       "2              0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from myfunk import *\n",
    "\n",
    "## --- Load Data\n",
    "p2data = pd.read_csv(path+'/data/p2_data.csv', index_col = 0, encoding = \"ISO-8859-1\") #simplest text encoding\n",
    "\n",
    "print(\"\\nData has {} unique Diagnosis\".format(len(p2data.Diagnosis.unique())))\n",
    "print(\"Data has {} unique ItemDescriptions\".format(len(p2data.ItemDescription.unique())))\n",
    "print(\"Data has {} unique PreventiveFlags:{} \\n {}\".format(len(p2data.PreventiveFlag.unique()),\n",
    "                                                           p2data.PreventiveFlag.unique(), \n",
    "                                                           p2data.PreventiveFlag.value_counts()))\n",
    "# Is the data balanced? \n",
    "print(\"Data has {} null PreventiveFlags\\n\".format(p2data.PreventiveFlag.isnull().sum()))\n",
    "\n",
    "# Divide training / testing datasets\n",
    "test = p2data.loc[p2data.PreventiveFlag.isnull()]\n",
    "data = p2data.loc[p2data.PreventiveFlag.notnull()]\n",
    "\n",
    "print(data.shape, test.shape)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4541 different words, numbers and symbols in the Item Description\n",
      "There are 2029 different words, numbers and symbols in the Diagnosis\n",
      "There are 4431 different non-stop words and numbers in the Item Description\n",
      "There are 1876 different non-stop words and numbers in the Item Description\n",
      "There are 4300 different lemmas, numbers and symbols in the Item Description\n",
      "There are 1731 different lemmas, numbers and symbols in the Diagnosis\n",
      "There are 4127 different stems & numbers in the Item Description\n",
      "There are 1631 different stems & numbers in the Diagnosis\n",
      "There are 4129 different stems of lemmas & numbers in the Item Description\n",
      "There are 1628 different stems of lemmas & numbers in the Diagnosis\n"
     ]
    }
   ],
   "source": [
    "eda_stemming_lemmatizing(data.ItemDescription.apply(lambda word: text_analysis(word)), \n",
    "                         data.Diagnosis.apply(lambda word: text_analysis(word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics for samples of class 1\n",
    "\n",
    "```python\n",
    "f, axarr = plt.subplots(2,3,figsize=(20,8))\n",
    "stats_class(data, f, axarr, 1.0) \n",
    "f.savefig(path+'/graphics/class1_stats.png', dpi=f.dpi)\n",
    "```\n",
    "![**Figure. **](graphics/class1_stats.png)\n",
    "\n",
    "#### Statistics for samples of class 0\n",
    "\n",
    "```python\n",
    "f, axarr = plt.subplots(2,3,figsize=(20,8))\n",
    "stats_class(data, f, axarr, 0.0)\n",
    "f.savefig(path+'/graphics/class0_stats.png', dpi=f.dpi)\n",
    "```\n",
    "![**Figure. **](graphics/class0_stats.png)\n",
    "Class 0 Item descritpion fields have a normal like distribution. The diagnosis field however has a few outliers with a character length exceeding 200. Some with over more than 6 sentences and words above 50 count. They seem to affect the prediction negatively, so I will remove them. \n",
    "\n",
    "#### Statistics for the whole dataset\n",
    "```python\n",
    "f, axarr = plt.subplots(2,3,figsize=(20,8))\n",
    "stats_overall(data, f, axarr)             \n",
    "f.savefig(path+'/graphics/dataset_stats.png', dpi=f.dpi)\n",
    "```\n",
    "![**Figure. **](graphics/dataset_stats.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Experiment Analysis\n",
    "\n",
    "As a preprocessing step the item descriptions and the diagnosis were blended and tokenized. I also remmoved some duplicated instances along with a couple of duplicated instances with different preventive flag values which I called contradictions and would act as noise for the classification. \n",
    "Another factor that wasn't relevant to the prediction was the pet name on the item's description. \n",
    "\n",
    "After text cleaning and removing stop words, there was over 6.3 thousand words to work with!\n",
    "\n",
    "The next steps include feature engineering. I converted the text corpus to a matrix of token counts (using CountVectorizer), then transform a count matrix to a normalized tf-idf representation (with tf-idf transformer). I used as feature selection method the chi-square test since it measures dependence between stochastic variables, so using this function “weeds out” the features that are the most likely to be independent of class and therefore irrelevant for classification.\n",
    "\n",
    "After that, I did a series of tests by training several classifiers from Scikit-Learn library (with default parameters)over different number of features, ngrams and the options of stemming (in this case), lemmatizing or both. The decision on whether to stem or not came from the fact that stemming gave higher performance scores. The training and validation splitting ratio was 70%:30% and the performance metric is the area under the curve (AUC) since it tells how much model is capable of distinguishing between classes and accuracy cannot show a reliable score due to the fact that the dataset is imbalanced. \n",
    "\n",
    "Python code to reproduce this figure:\n",
    "```python\n",
    "results = pd.read_csv(path+\"/results/experimentation_results.csv\", index_col=0)\n",
    "fig = nGrams_distribution(results, 'Val', 5, 'AUC', 1)\n",
    "fig.savefig(path+'/graphics/StemmingAUCdistributions.png', dpi=fig.dpi)\n",
    "```\n",
    "![**Figure. **](graphics/StemmingAUCdistributions.png)\n",
    "The figure above shows the distribution of the performance score AUC of each of the classifiers. I divided the results by n-grams and by their dimensionality divided by 2 quartiles (low < 0.3, mid and high > 0.6). The 3rd column (showing the distributions with the number of features above 4000) doesn't show the distribution with 1-grams because the maximum number of 1-grams extracted from the training set was below the limit of 4000. However the number of combinations with 2-grams and 3-grams exceeded that limit. \n",
    "\n",
    "The random forest (RF) along with the SVM with gradient descent (SGD) perform best at low dimensions and 1-grams. The decision trees (DT) classifier outperforms them but its performance decreases as the dimensionality increases. \n",
    "\n",
    "The Gaussian NB (GNB) classifier, on the other hand, stabilizes around .858 (AUC score) and 2-grams as the number of dimensions increase. This clf also shows a competitive AUC score above 80%. \n",
    "As for the Adaboost classifier (AB), shows a high score in the low dimensions with the more n-grams the better. \n",
    "\n",
    "So there is a tradeoff between the number of features and the number of ngrams. The RF and SGD showing low performance (below 80%) must leave the race. The GNB performs better with higher dimensionality. AB performs better with higher n-grams and DT performs better with a low dimensionality and low ngrams. A balanced model with a set of these last 3 classifiers could have as parameters n-grams=2 and a mid-size dimensionality. \n",
    "\n",
    "Python code to reproduce this figure:\n",
    "```python\n",
    "# from sklearn import preprocessing\n",
    "selected_baseline = ('DecisionTreeClassifier','GaussianNB','AdaBoostClassifier')\n",
    "\n",
    "# cols = ['Phase','AUC', 'F1_C0', 'F1_C1', 'MSE', 'Prec_C0', 'Prec_C1', 'Recal_C0', 'Recal_C1','nFeats']\n",
    "cols = ['Phase','AUC','nFeats']\n",
    "res = results.loc[results.Phase.str.endswith(('DecisionTreeClassifier','GaussianNB','AdaBoostClassifier')),cols]\\\n",
    "            .groupby(['Phase','nFeats']).mean().reset_index()\n",
    "\n",
    "cols = np.repeat(res.columns[2:].values,2)\n",
    "fig, axes = plt.subplots(nrows = res.shape[1]-2, ncols = 2, figsize=(20,5*(res.shape[1]-2)))\n",
    "plot_dimensionality_series(fig, axes, res, cols)\n",
    "fig.savefig(path+'/graphics/auc_over_dimensions.png', dpi=fig.dpi)\n",
    "```\n",
    "![**Figure. **](graphics/auc_over_dimensions.png)\n",
    "The figure (above) shows the AUC score over the number of features and the red line is a normalized sum of those scores. Since I chose the mid section of amount of features (2350-3850) the classifiers show a peak on ensemble score at 3100. I used this value as a reference to compare with the voting score of the remaining values of the number of features (nFeats)\n",
    "\n",
    "The best nFeats value came out to be 3550. I did another test but this time with a training/validation split of 80%:20% (a rule of thumb) and the model yield a higher score for 4200 features.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Definition of Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## ---------------------\n",
    "## --- Variables\n",
    "## ---------------------\n",
    "ng = 2                       # N gramms\n",
    "lemaVsStem = 1               # [0 for Lemming, 1 for stemming, 2 for both, 5 for none]\n",
    "k = 4200                     # Optimal number of features. \n",
    "seed = 42                    # To minimize the sampling variation. \n",
    "train_val_ratio = 0.2        # Rule of thumb (see Pareto principle)\n",
    "resample_dataset = False     # Method to overcome the effect of an imbalanced dataset (Showed lower performance)\n",
    "optimal_ratios = [1,1]       # Option2: [0.4,0.244]\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "# Baseline classifiers: \n",
    "clf_base = {\n",
    "    'clf_1':DecisionTreeClassifier(random_state=seed),\n",
    "    'clf_2':AdaBoostClassifier(DecisionTreeClassifier(max_depth=2), random_state=seed), \n",
    "    'clf_3':GaussianNB()}    \n",
    "\n",
    "\n",
    "# Optimal baseline params: \n",
    "clf_opt = {\n",
    "    'clf_1': DecisionTreeClassifier(max_depth=17,\n",
    "             max_leaf_nodes=42,min_samples_split=12,random_state=seed), \n",
    "    'clf_2': AdaBoostClassifier(algorithm='SAMME.R',\n",
    "           base_estimator=DecisionTreeClassifier(max_depth=2,min_samples_split=2,random_state=seed),\n",
    "           learning_rate=0.9, n_estimators=64, random_state=42), \n",
    "    'clf_3': GaussianNB()}\n",
    "\n",
    "\n",
    "# Pipeline with Preprocessing functions and soft voting ensemble method\n",
    "kbest = SelectKBest(chi2, k=4200) # Feature selection\n",
    "sVoting = VotingClassifier(estimators=[(k,v) for k,v in clf_opt.items()], voting='soft')\n",
    "mixed_pipe = Pipeline([('kbest', kbest), ('SoftVoting', sVoting)])\n",
    "\n",
    "\n",
    "# Flags\n",
    "flags = {'lemStem':lemaVsStem, 'optimalRatio':optimal_ratios,'resample': resample_dataset, \n",
    "         'trainValRatio': train_val_ratio,'n-grams': ng, 'N_Models':len(clf_opt),'rndseed':seed,\n",
    "         'customVocabulary':False,'keepDupes':True,'path':path,'name': None,'optimalK': k}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5. Baseline vs Tuned models\n",
    "\n",
    "\n",
    "The figure below shows the score comparison between the selected classifiers (exp1) with default parameters vs with tuned parameters (exp2): \n",
    "```python \n",
    "## --- Training and validation of Basline and Tuned Classifiers\n",
    "# These 2 functions will train the data and get the individual scores for each classifier in the set\n",
    "# ETA ~ 14min\n",
    "df_baseline = trupanion(data, clf_base, flags, 2)  # 7min\n",
    "df_tuned = trupanion(data, clf_opt, flags, 2) # 7 min\n",
    "\n",
    "## --- Metrics\n",
    "# Plot baseline compared with tuned clfs\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize=(20,8))\n",
    "cols = ['MSE', 'AUC', 'F1_C0', 'F1_C1', 'Prec_C0', 'Prec_C1','Recal_C0', 'Recal_C1']\n",
    "comparisson_clfs(fig, axes, \n",
    "                 df_baseline.loc[(df_baseline.Phase=='Val Soft')|(df_baseline.Phase=='Val Hard')], \n",
    "                 df_tuned.loc[(df_tuned.Phase=='Val Soft')|(df_tuned.Phase=='Val Hard')],  \n",
    "                 cols, 0.35)\n",
    "fig.savefig(path+'/graphics/baselineVsOptimized.png', dpi=fig.dpi)\n",
    "```\n",
    "![**Figure. **](graphics/baselineVsOptimized.png)\n",
    "There's an improvement on the AUC score of 1% using the tuned classifiers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6. Training and Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n",
      "Stemming...\n",
      "Splitting datasets into training and validation sets...\n",
      "Vectorizing...\n",
      "Using default vocabulary\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "Extracting features from the test data using the same vectorizer\n",
      "Data shape, Training and validation sizes:(9958, 3), (7966, 19323), 7966,(1992, 19323),1992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1_C0</th>\n",
       "      <th>F1_C1</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Prec_C0</th>\n",
       "      <th>Prec_C1</th>\n",
       "      <th>Recal_C0</th>\n",
       "      <th>Recal_C1</th>\n",
       "      <th>db_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.780</td>\n",
       "      <td>(7966, 19323)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.772</td>\n",
       "      <td>(1992, 19323)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AUC  F1_C0  F1_C1    MSE  Prec_C0  Prec_C1  Recal_C0  Recal_C1  \\\n",
       "Training    0.882  0.984  0.779  0.029    0.984    0.777     0.984     0.780   \n",
       "Validation  0.878  0.983  0.782  0.032    0.982    0.793     0.984     0.772   \n",
       "\n",
       "                  db_size  \n",
       "Training    (7966, 19323)  \n",
       "Validation  (1992, 19323)  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ETA ~ 274 s\n",
    "\n",
    "## --- Preprocessing\n",
    "X_train, X_val, y_train, y_val, feature_names, vCounter, vTfidf = m_preprocess(data, flags, 0)\n",
    "\n",
    "## --- Training and Prediction \n",
    "mixed_pipe.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = cross_val_predict(mixed_pipe, X_train, y_train, cv=10)   \n",
    "y_val_pred = mixed_pipe.predict(X_val)\n",
    "\n",
    "## --- Evaluation metrics\n",
    "res = get_metrics_biz(pd.DataFrame(), y_train, y_train_pred, X_train.shape, 'Training')\n",
    "res = get_metrics_biz(res, y_val, y_val_pred, X_val.shape, 'Validation')\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 7. Results\n",
    "\n",
    "```python\n",
    "fig, axarr = plt.subplots(1,2,figsize=(15,4))\n",
    "plot_curves(fig, axarr, y_train, y_train_pred, y_val, y_val_pred)\n",
    "fig.savefig(path+'/graphics/TrainValRoCurve.png', dpi=fig.dpi)\n",
    "```\n",
    "![**Figure. **](graphics/TrainValRoCurve.png)\n",
    "\n",
    "From the ROC curve (TPR vs FPR) above, it's shown that the scores on both (Validation and Training) sets are pretty much alike, thus it is less likely the model is overfitting.\n",
    "\n",
    "The true positive rate (TPR or Recall) in the vertical axis almost reaches 0.8 with an almost non existing false positives. \n",
    "However, if we care about maximizing true positives, I will have to decrease the cut-off. This way more events will be classified as class 1, some will be true ones however the false positive rate will also increase and 20% more will be false positives. This is the business decision. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 8. Prediction of the Test set:     ~ 40s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n",
      "Stemming...\n",
      "Stemming...\n",
      "Vectorizing...\n",
      "Using default vocabulary\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "Extracting features from the test data using the same vectorizer\n",
      "Data shape, Training and validation sizes:(9958, 3), (9958, 21980), 9958,(1000, 21980),1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>test_sample_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     outcome  test_sample_id\n",
       "0        0.0           10001\n",
       "1        0.0           10002\n",
       "2        0.0           10003\n",
       "3        0.0           10004\n",
       "4        0.0           10005\n",
       "5        0.0           10006\n",
       "6        0.0           10007\n",
       "7        0.0           10008\n",
       "8        0.0           10009\n",
       "9        0.0           10010\n",
       "10       0.0           10011\n",
       "11       0.0           10012\n",
       "12       0.0           10013\n",
       "13       0.0           10014\n",
       "14       0.0           10015\n",
       "15       0.0           10016\n",
       "16       0.0           10017\n",
       "17       0.0           10018\n",
       "18       0.0           10019\n",
       "19       0.0           10020\n",
       "20       0.0           10021\n",
       "21       0.0           10022\n",
       "22       0.0           10023\n",
       "23       0.0           10024\n",
       "24       0.0           10025\n",
       "25       0.0           10026\n",
       "26       0.0           10027\n",
       "27       0.0           10028\n",
       "28       0.0           10029\n",
       "29       0.0           10030\n",
       "..       ...             ...\n",
       "970      0.0           10971\n",
       "971      0.0           10972\n",
       "972      0.0           10973\n",
       "973      0.0           10974\n",
       "974      0.0           10975\n",
       "975      0.0           10976\n",
       "976      0.0           10977\n",
       "977      0.0           10978\n",
       "978      0.0           10979\n",
       "979      0.0           10980\n",
       "980      0.0           10981\n",
       "981      0.0           10982\n",
       "982      0.0           10983\n",
       "983      0.0           10984\n",
       "984      0.0           10985\n",
       "985      0.0           10986\n",
       "986      0.0           10987\n",
       "987      1.0           10988\n",
       "988      0.0           10989\n",
       "989      1.0           10990\n",
       "990      0.0           10991\n",
       "991      0.0           10992\n",
       "992      0.0           10993\n",
       "993      0.0           10994\n",
       "994      0.0           10995\n",
       "995      0.0           10996\n",
       "996      0.0           10997\n",
       "997      0.0           10998\n",
       "998      0.0           10999\n",
       "999      0.0           11000\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## --- Preprocessing \n",
    "# Joining the training and validation set into one.\n",
    "X_train, X_test, y_train, trash, feature_names, vCounter, vTfidf = m_preprocess(data, flags, test)\n",
    "\n",
    "## --- Training and Prediction: \n",
    "mixed_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Test Set Predictions\n",
    "test_preds = mixed_pipe.predict(X_test)\n",
    "\n",
    "# Format for submission\n",
    "output = pd.DataFrame({ 'test_sample_id' : test.index, 'outcome': test_preds })\n",
    "output.to_csv(path+\"/results/predictions.csv\", index = False)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/iZbra1/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1_C0</th>\n",
       "      <th>F1_C1</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Prec_C0</th>\n",
       "      <th>Prec_C1</th>\n",
       "      <th>Recal_C0</th>\n",
       "      <th>Recal_C1</th>\n",
       "      <th>db_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.713</td>\n",
       "      <td>(9958, 21980)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AUC  F1_C0  F1_C1   MSE  Prec_C0  Prec_C1  Recal_C0  Recal_C1  \\\n",
       "Training  0.846  0.978  0.707  0.04    0.979    0.701     0.978     0.713   \n",
       "\n",
       "                db_size  \n",
       "Training  (9958, 21980)  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training scores: \n",
    "# ETA: ~322 s\n",
    "\n",
    "y_train_pred = cross_val_predict(mixed_pipe, X_train, y_train, cv=10)   \n",
    "res = get_metrics_biz(pd.DataFrame(), y_train, y_train_pred, X_train.shape, 'Training')\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "fig, axarr = plt.subplots(1,2,figsize=(15,4))\n",
    "plot_curves(fig, axarr, y_train, y_train_pred)\n",
    "fig.savefig(path+'/graphics/TrainRoCurve.png', dpi=fig.dpi)\n",
    "```\n",
    "![**Figure. **](graphics/TrainRoCurve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Conclusion\n",
    "\n",
    "The AUC score lowered as expected since more variance was added thanks to the data samples from the validation set. But it is important to know that the more data samples we have, the less likely the model will tend to overfit. \n",
    "\n",
    "To compensate the class imbalance, I attempted to ensemble different resampled datasets. This consisted in dividing the instances of class 1 in 3 unequal segments where each segment would be concatenated with all of the class 0 (the minority) instances and assign a classifyier to them. However that didnt improve the baseline's score. Another option could have been to include more features pertaining to the minority class and even expand the set with a higher value for n-grams. Also if I had more free time to work on this project, I'd check the option of finding Word2vecs that could be clustered for each class. \n",
    "\n",
    "On another note, the duplicates affected positively in the classification. In the dataset with (said) outliers and duplicates, the validation score showed the highest AUC as well as the rest of the metrics. However in the final classification where the validation set is merged with the training data, the removal of outliers showed to have the highest AUC score and the recall of the minority class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3 – Short answer\n",
    "As an insurance company, we collect premium on a monthly basis from customers. In return, we pay the customer’s veterinary bills should their pets receive medical treatment.\n",
    "- How would you estimate the expected value of a customer at any given point in time?\n",
    "- In what ways could we utilize this estimate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im assuming that the expected value is the expected value of loss for the company. In that view, a valuable customer affects with a minimal loss, that is: \n",
    "Cumulated premiums - Total amount in bills  (for any given point in time)\n",
    "\n",
    "However when a new customer applies for insurance, its value can’t be determined by that formula. So in this case I would start with some biased value.  This bias will approximate to the correct prediction of a hypothetical loss. For that it should:\n",
    "\n",
    "1. Predict the probability of the pet receiving medical treatment with high confidence. \n",
    "2. Predict whether the customer will/can pay the premiums on time and in its totality. \n",
    "\n",
    "That way I’d have an idea of the frequency and purpose of the medical assistance to calculate a hypothetical loss. \n",
    "\n",
    "In what ways could we utilize this estimate?\n",
    "\n",
    "For starters, predicting the bias of a customer can reveal (with a clustering algorithm) aspects of different types of customer that can adjust to certain types of policies or insurance packages with different payment and medical assistance options that would steer the whole outcome into a minimal loss. \n",
    "\n",
    "In other words, understanding the customer's attributes, can help provide the adequate insurance. \n",
    "\n",
    "Moreover the temporal aspect of the value of the customer can give out patterns which can be useful as it encourages the insurance company to anticipate to high loss. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
