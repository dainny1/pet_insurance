{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11000 entries, 1 to 11000\n",
      "Data columns (total 3 columns):\n",
      "ItemDescription    11000 non-null object\n",
      "Diagnosis          11000 non-null object\n",
      "PreventiveFlag     10000 non-null float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 343.8+ KB\n",
      "None\n",
      "\n",
      "Data has 2266 unique Diagnosis\n",
      "Data has 10475 unique ItemDescriptions\n",
      "Data has 3 unique PreventiveFlags:[ 0.  1. nan] \n",
      " 0.0    9322\n",
      "1.0     678\n",
      "Name: PreventiveFlag, dtype: int64\n",
      "Data has 1000 null PreventiveFlags\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemDescription</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>PreventiveFlag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Six:  Urgent Care Exam - Daytime (8am-6pm)</td>\n",
       "      <td>colitis</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jafar:  Office Visit/Physical Exam</td>\n",
       "      <td>Stomach Issues</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jafar:  Fecal Smears</td>\n",
       "      <td>Stomach Issues</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jafar:  metronidazole 50mg</td>\n",
       "      <td>Stomach Issues</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jafar:  Fecal analysis for parasites</td>\n",
       "      <td>Stomach Issues</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ItemDescription        Diagnosis  \\\n",
       "id                                                                \n",
       "1   Six:  Urgent Care Exam - Daytime (8am-6pm)         colitis    \n",
       "2           Jafar:  Office Visit/Physical Exam  Stomach Issues    \n",
       "3                        Jafar:  Fecal Smears   Stomach Issues    \n",
       "4                   Jafar:  metronidazole 50mg  Stomach Issues    \n",
       "5         Jafar:  Fecal analysis for parasites  Stomach Issues    \n",
       "\n",
       "    PreventiveFlag  \n",
       "id                  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "5              0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2data = pd.read_csv('p2_data.csv', index_col = 0, encoding = \"ISO-8859-1\") #simplest text encoding\n",
    "print(p2data.info())\n",
    "print(\"\\nData has {} unique Diagnosis\".format(len(p2data.Diagnosis.unique())))\n",
    "print(\"Data has {} unique ItemDescriptions\".format(len(p2data.ItemDescription.unique())))\n",
    "print(\"Data has {} unique PreventiveFlags:{} \\n {}\".format(len(p2data.PreventiveFlag.unique()),\n",
    "                                                           p2data.PreventiveFlag.unique(), \n",
    "                                                           p2data.PreventiveFlag.value_counts()))\n",
    "print(\"Data has {} null PreventiveFlags\\n\".format(p2data.PreventiveFlag.isnull().sum()))\n",
    "p2data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemDescription</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>PreventiveFlag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Six:  Urgent Care Exam - Daytime (8am-6pm)</td>\n",
       "      <td>colitis</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jafar:  Office Visit/Physical Exam</td>\n",
       "      <td>Stomach Issues</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jafar:  Fecal Smears</td>\n",
       "      <td>Stomach Issues</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jafar:  metronidazole 50mg</td>\n",
       "      <td>Stomach Issues</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jafar:  Fecal analysis for parasites</td>\n",
       "      <td>Stomach Issues</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ItemDescription        Diagnosis  \\\n",
       "id                                                                \n",
       "1   Six:  Urgent Care Exam - Daytime (8am-6pm)         colitis    \n",
       "2           Jafar:  Office Visit/Physical Exam  Stomach Issues    \n",
       "3                        Jafar:  Fecal Smears   Stomach Issues    \n",
       "4                   Jafar:  metronidazole 50mg  Stomach Issues    \n",
       "5         Jafar:  Fecal analysis for parasites  Stomach Issues    \n",
       "\n",
       "    PreventiveFlag  \n",
       "id                  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "5              0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = p2data.loc[p2data.PreventiveFlag.notnull()]\n",
    "# data = data.sample(frac=0.05)\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, word_tokenize\n",
    "from time import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0678 Label 1 vs 0.9322 Label 0\n"
     ]
    }
   ],
   "source": [
    "# Is the data balanced? \n",
    "label_true = data.PreventiveFlag.value_counts()[1]\n",
    "label_false = data.PreventiveFlag.value_counts()[0]\n",
    "print(\"{} Label 1 vs {} Label 0\".format(str(label_true/(label_false+label_true)),\n",
    "                         str(label_false/(label_false+label_true))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ItemDescription'] = data.ItemDescription.apply(remove_punctuation2)\n",
    "data['Diagnosis'] = data.Diagnosis.apply(remove_punctuation1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming or Lemmatization?\n",
    "stemmer = PorterStemmer()\n",
    "data['ItemDescription'] = data.ItemDescription.apply(lambda text: \" \".join([stemmer.stem(word) for word in text.split()]))\n",
    "data['Diagnosis'] = data.Diagnosis.apply(lambda text: \" \".join([stemmer.stem(word) for word in text.split()]))\n",
    "\n",
    "lemmer = WordNetLemmatizer()\n",
    "# data['ItemDescription'] = data.ItemDescription.apply(lambda text: \" \".join([lemmer.lemmatize(word, pos=\"v\") for word in text.split()]))\n",
    "# data['Diagnosis'] = data.Diagnosis.apply(lambda text: \" \".join([lemmer.lemmatize(word, pos=\"v\") for word in text.split()]))\n",
    "data.head()\n",
    "# # Remove stopwords in diagnosis... maybe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/iZbra1/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace slash with space\n",
    "# Remove punctuation and extra spaces\n",
    "# Convert to lower case ?? Not the Item Description, yes for diagnosis\n",
    "def remove_punctuation1(i_desc):\n",
    "    pattern = r\"[^\\w\\s]\"\n",
    "    idesc = re.sub(r\"/\", ' ', i_desc).lower()\n",
    "    return \" \".join(re.sub(pattern, '', idesc).split()) \n",
    "\n",
    "# Just word_tokenize: for ItemDescription\n",
    "# The first word on the IDesc is a proper name. \n",
    "def remove_punctuation2(i_desc):\n",
    "    return \" \".join(word_tokenize(i_desc))\n",
    "\n",
    "def preprocessing(df):\n",
    "    \n",
    "    # Remove punctuation\n",
    "    df['ItemDescription'] = df.ItemDescription.apply(remove_punctuation2)\n",
    "    df['Diagnosis'] = df.Diagnosis.apply(remove_punctuation1)\n",
    "    \n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    df['ItemDescription'] = df.ItemDescription.apply(lambda text: \" \".join([stemmer.stem(word) for word in text.split()]))\n",
    "    df['Diagnosis'] = df.Diagnosis.apply(lambda text: \" \".join([stemmer.stem(word) for word in text.split()]))\n",
    "    \n",
    "    # Lemming\n",
    "#     lemmer = WordNetLemmatizer()\n",
    "#     data['ItemDescription'] = data.ItemDescription.apply(lambda text: \" \".join([lemmer.lemmatize(word, pos=\"v\") for word in text.split()]))\n",
    "#     data['Diagnosis'] = data.Diagnosis.apply(lambda text: \" \".join([lemmer.lemmatize(word, pos=\"v\") for word in text.split()]))\n",
    "\n",
    "    return df.ItemDescription.values + \" \" + df.Diagnosis.values\n",
    "    \n",
    "def vectorizer(train, corpus_all, vectorizer_count, vectorizer_tf):\n",
    "    \n",
    "    # Model: \n",
    "    #  vectorizer.vocabulary_\n",
    "    #  vectorizer.get_feature_names()\n",
    "    \n",
    "    if train:\n",
    "        vectorizer_count = CountVectorizer(token_pattern='[a-zA-Z]{2,}', stop_words='english')\n",
    "        one_hot = vectorizer_count.fit_transform(corpus_all)\n",
    "    else: \n",
    "        vectorizer_count._validate_vocabulary()\n",
    "        one_hot = vectorizer_count.transform(corpus_all)\n",
    "    \n",
    "    # TFIDF\n",
    "    # Term frequency: this summarizes how often a given word appears within a document\n",
    "    # Inverse document frequency: This downscales words that appear a lot across documents\n",
    "    # Transforming the matrix based on the learnt frequencies or weights\n",
    "    # vectorizer_tf.idf_\n",
    "    \n",
    "    if train:\n",
    "        vectorizer_tf = TfidfTransformer()\n",
    "        freq = vectorizer_tf.fit_transform(one_hot)\n",
    "    else: \n",
    "        freq = vectorizer_tf.transform(one_hot)\n",
    "    \n",
    "    return freq.toarray(), vectorizer_count, vectorizer_tf\n",
    "\n",
    "def get_metrics(df, y, yp, ys=True):\n",
    "# Evaluation Metrics:\n",
    "\n",
    "    d_roc = round(roc_auc_score(y, yp),3)\n",
    "    d_mse = round(mean_squared_error(y, yp),3)\n",
    "    d_prec = precision_score(y, yp, average=None)\n",
    "    d_recl = recall_score(y, yp, average=None)\n",
    "    d_f1 = f1_score(y, yp, average=None)\n",
    "#     d_report = metrics.classification_report(y, yp, target_names=['class 0', 'class 1'])\n",
    "\n",
    "    if isinstance(ys, np.ndarray):\n",
    "        ind_name = 'Training'\n",
    "        d_acc = round(ys.mean(),3)\n",
    "    else: \n",
    "        #### Validation\n",
    "        ind_name = \"Validation\"\n",
    "        d_acc = round(accuracy_score(y, yp),3)\n",
    "\n",
    "    return pd.concat([df, pd.DataFrame({'Acc':d_acc, \n",
    "                            'Prec_C0':round(d_prec[0],3),\n",
    "                            'Prec_C1':round(d_prec[1],3),\n",
    "                            'Recal_C0':round(d_recl[0],3),\n",
    "                            'Recal_C1':round(d_recl[1],3),\n",
    "                            'F1_C0':round(d_f1[0],3),\n",
    "                            'F1_C1':round(d_f1[1],3),\n",
    "                            'AUC':d_roc, \n",
    "                            'MSE':d_mse}, index=[ind_name])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7982, 4877) (7982,) (2018, 4877) (2018,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset\n",
    "\n",
    "test = p2data.loc[p2data.PreventiveFlag.isnull()]\n",
    "data = p2data.loc[p2data.PreventiveFlag.notnull()]\n",
    "\n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "\n",
    "train = preprocessing(data[msk])\n",
    "validation = preprocessing(data[~msk])\n",
    "\n",
    "X_train, vc, vt = vectorizer(True, train, False, False)\n",
    "y_train = data[msk].PreventiveFlag.values\n",
    "\n",
    "X_val, vc, vt = vectorizer(False, validation, vc, vt)\n",
    "y_val = data[~msk].PreventiveFlag.values\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, \\\n",
    "                            mean_squared_error, accuracy_score, f1_score, \\\n",
    "                            precision_score, recall_score\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal classifiers. \n",
    "clf1 = DecisionTreeClassifier(max_depth=2, max_leaf_nodes=42, min_samples_split=2, random_state=42)\n",
    "clf2 = SGDClassifier(learning_rate='optimal', loss='log', max_iter=4, penalty='l1', random_state=42)\n",
    "clf3 = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "\n",
    "clfs = [\n",
    "    (\"DecTree\", clf1),\n",
    "    (\"SVMwithSGD\", clf2),\n",
    "    (\"LogReg\", clf3)\n",
    "]\n",
    "\n",
    "mixed_pipe = Pipeline([\n",
    "    (\"voting\", VotingClassifier(clfs, voting=\"soft\"))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.47010803222656\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "mixed_pipe.fit(X_train, y_train)\n",
    "y_val_pred = mixed_pipe.predict(X_val)\n",
    "\n",
    "# These predictions can then be used to evaluate the classifier:\n",
    "\n",
    "y_train_scores = cross_val_score(mixed_pipe, X_train, y_train, cv=10)\n",
    "y_train_pred = cross_val_predict(mixed_pipe, X_train, y_train, cv=10)\n",
    "\n",
    "print(time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Acc</th>\n",
       "      <th>F1_C0</th>\n",
       "      <th>F1_C1</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Prec_C0</th>\n",
       "      <th>Prec_C1</th>\n",
       "      <th>Recal_C0</th>\n",
       "      <th>Recal_C1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training</th>\n",
       "      <td>0.760</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation</th>\n",
       "      <td>0.815</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AUC    Acc  F1_C0  F1_C1    MSE  Prec_C0  Prec_C1  Recal_C0  \\\n",
       "Training    0.760  0.961  0.979  0.649  0.039    0.966    0.843     0.993   \n",
       "Validation  0.815  0.969  0.983  0.725  0.031    0.976    0.838     0.992   \n",
       "\n",
       "            Recal_C1  \n",
       "Training       0.527  \n",
       "Validation     0.638  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = get_metrics(pd.DataFrame(), y_train, y_train_pred, y_train_scores)\n",
    "res = get_metrics(res, y_val, y_val_pred, False)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer: \n",
    "- Dealing with unbalanced dataset: \n",
    "    - Even up the training set: train the model with all of the minority class instances and an almost same amount of instances of the majority class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_test = preprocessing(test, False)\n",
    "y_test = test.PreventiveFlag.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
